{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('tf2': conda)"
  },
  "interpreter": {
   "hash": "c2261f3df2972a80505f08078dab8823f6e28fc5b680b9d0aa1c41eb25d20a7a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pretty print library to get better output\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train.txt\n",
    "with open(\"dataset/train.txt\") as f:\n",
    "    # declare an empty list for later saving train data values\n",
    "    train_value = []\n",
    "    predict_value = []\n",
    "\n",
    "    # read the train values line by line\n",
    "    for line in f:\n",
    "        # seperate every sequence number by comma\n",
    "        sep_string = line.split(',')\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        # using slice of list to get the value we acctually need\n",
    "        while(count < 2):\n",
    "            # first and second number sequence need the last three digits\n",
    "            sep_string[count] = sep_string[count][-3:]\n",
    "            count += 1\n",
    "        \n",
    "        # the third number sequence need last four digits and no '\\n'\n",
    "        sep_string[2] = sep_string[2][-5:-1]\n",
    "        train_value.append(sep_string[:2])\n",
    "        predict_value.append(sep_string[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "split_percent = 0.80\n",
    "\n",
    "split = int(split_percent*len(train_value))\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200000\n50000\n"
     ]
    }
   ],
   "source": [
    "tra_val = train_value[:split]\n",
    "tra_prd = predict_value[:split]\n",
    "\n",
    "vld_val = train_value[split:]\n",
    "vld_prd = predict_value[split:]\n",
    "\n",
    "print(len(tra_val))\n",
    "print(len(vld_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['686', '617'], ['643', '401'], ['375', '414'], ['476', '627'], ['431', '387']]\n['4983', '2824', '1601', '4023', '1638']\n[['394', '377'], ['512', '378'], ['773', '772'], ['798', '466'], ['403', '446']]\n['1363', '1962', '6813', '4184', '2029']\n"
     ]
    }
   ],
   "source": [
    "# show first five train value\n",
    "pp.pprint(tra_val[:5])\n",
    "\n",
    "# show first five train predict\n",
    "pp.pprint(tra_prd[:5])\n",
    "\n",
    "# show first five validation value\n",
    "pp.pprint(vld_val[:5])\n",
    "\n",
    "# show first five validation predict\n",
    "pp.pprint(vld_prd[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "\n",
    "train_generator = TimeseriesGenerator(tra_val, tra_prd, length=look_back, batch_size=128)\n",
    "test_generator = TimeseriesGenerator(vld_val, vld_prd, length=look_back, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DENPO\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3685054.9595\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2258993.4727\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2258495.7072\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2256922.0743\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2254935.0050\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2252820.5476\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2250329.4177\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2248650.8365\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2247499.2086\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2246263.1492\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2245408.0021\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2244875.8075\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2244667.9906\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2244384.6991\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2244147.1450\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2243518.5799\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2243636.5131\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2243634.7106\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2243799.0298\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2243402.3234\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x216509e3388>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(10,\n",
    "        activation='relu',\n",
    "        input_shape=(look_back,2))\n",
    ")\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, epochs=num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "array([[3940.3088],\n       [4001.8835],\n       [4053.0159],\n       ...,\n       [4233.6978],\n       [4235.0586],\n       [4316.515 ]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}